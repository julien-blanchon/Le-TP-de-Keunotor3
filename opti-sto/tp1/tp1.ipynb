{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression linéaire et gradient stochastique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce TD-TP a pour objectif de plonger de manière un peu plus individualisée dans le cours d’optimisation stochastique. Il n’est pas noté, mais j’encourage très vivement les étudiants à rédiger consciencieusement leurs réponses et leurs idées.\n",
    "\n",
    "La rédaction force à mieux présenter les choses et surtout à mieux les cerner. Ca me permettra aussi plus facilement de corriger d’éventuelles incompréhensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’objectif de ce TP est d’illustrer la première partie du cours d’optimisation stochastique sur les erreurs en apprentissage et d’implémenter les premières versions du gradient stochastique. Il a aussi pour objectif de vous entraîner à effectuer des calculs avec des variables aléatoires pour les rendre plus accessibles et mieux comprendre les cours à venir.\n",
    "\n",
    "Nous allons nous placer dans le cadre de travail le plus simple : la régression linéaire. Ce cadre présente plusieurs avantages :\n",
    "- C’est probablement le plus simple d’un point de vue théorique et il permet d’appréhender de nombreux phénomènes avec des mathématiques relativement élémentaires.\n",
    "- C’est probablement encore le plus utilisé dans les applications, et il me semble nécessaire de le comprendre profondément."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Le cadre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit $X$ un vecteur aléatoire de $\\mathbb{R}^d$, pour $d ∈ \\mathbb{N}$ suivant une certaine distribution de probabilité inconnue $P_X$. Pour un certain vecteur $θ ∈ \\mathbb{R}^d$, on construit une variable aléatoire $Y ∈ \\mathbb{R}$ définie par $Y = hθ$, $Xi + B$ où $B ∼ N(0, σ^2)$ est une variable aléatoire gaussienne indépendante de $X$.\n",
    "\n",
    "L’objectif de ce TP est d’apprendre le vecteur $θ$ inconnu à partir de $n ∈ \\mathbb{N}$ observations $(x_i, y_i)_{1≤i≤n}$ tirées indépendamment suivant la loi $P$.\n",
    "\n",
    "Pour ce faire, on peut simplement résoudre le problème de minimisation du risque empirique suivant :\n",
    "\n",
    "$$\\inf _{w \\in \\mathbb{R}^{d}} E_{n}(w)=\\frac{1}{2 n} \\sum_{i=1}^{n}\\left(\\left\\langle w, x_{i}\\right\\rangle-y_{i}\\right)^{2}$$\n",
    "\n",
    "On notera $w^∗_n$ n’importe quel minimiseur (sous réserve d’existence) du problème ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
